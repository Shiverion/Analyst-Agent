{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11864712",
   "metadata": {},
   "source": [
    "# 🤖 Agentic Data Analysis with LangChain and Gradio\n",
    "\n",
    "This notebook documents the setup, code, and execution of a web application that uses a LangChain agent to perform data analysis on user-uploaded CSV files. The interface is built with Gradio, and the project environment is managed by `uv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134cdd72",
   "metadata": {},
   "source": [
    "## Step 1: Project Setup with `uv`\n",
    "\n",
    "We use `uv`, a fast Python package manager from Astral, to handle our project's virtual environment and dependencies. This ensures a clean, reproducible setup.\n",
    "\n",
    "### 1.1 - Install `uv`\n",
    "\n",
    "If you don't have `uv` installed, run the following command in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c668a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sh' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# On macOS / Linux\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# On Windows (in PowerShell)\n",
    "# powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961ef1a",
   "metadata": {},
   "source": [
    "### 1.2 - Initialize Project and Install Dependencies\n",
    "\n",
    "Create a project directory, initialize it, and add the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "157d81b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Project is already initialized in `\u001b[36mc:\\Users\\miqba\\projects\\Analyst_Agent_with_Langchain\u001b[39m` (`pyproject.toml` file exists)\n",
      "Using CPython 3.12.3 interpreter at: \u001b[36mC:\\Users\\miqba\\anaconda3\\python.exe\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[31muv::venv::creation\u001b[0m\n",
      "\n",
      "  \u001b[31m×\u001b[0m Failed to create virtualenv\n",
      "\u001b[31m  ╰─▶ \u001b[0mfailed to remove directory\n",
      "\u001b[31m      \u001b[0m`c:\\Users\\miqba\\projects\\Analyst_Agent_with_Langchain\\.venv`: Access is\n",
      "\u001b[31m      \u001b[0mdenied. (os error 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m130 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m122 packages\u001b[0m \u001b[2min 8.56s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==24.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.12.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbrotli\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdataclasses-json\u001b[0m\u001b[2m==0.6.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdotenv\u001b[0m\u001b[2m==0.9.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.116.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mffmpy\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.18.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.59.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.41.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgreenlet\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgroovy\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.34.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjiter\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpatch\u001b[0m\u001b[2m==1.33\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpointer\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain\u001b[0m\u001b[2m==0.3.27\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-community\u001b[0m\u001b[2m==0.3.27\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.3.72\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-experimental\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-openai\u001b[0m\u001b[2m==0.3.28\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==0.3.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.4.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarshmallow\u001b[0m\u001b[2m==3.26.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.99.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.11.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydub\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpywin32\u001b[0m\u001b[2m==311\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2025.7.34\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-toolbelt\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.12.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafehttpx\u001b[0m\u001b[2m==0.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msemantic-version\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msqlalchemy\u001b[0m\u001b[2m==2.0.42\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.47.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtenacity\u001b[0m\u001b[2m==9.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspect\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.35.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.20.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzstandard\u001b[0m\u001b[2m==0.23.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!mkdir agentic-data-app\n",
    "!cd agentic-data-app\n",
    "!uv init\n",
    "!uv venv\n",
    "!uv add langchain langchain-openai pandas matplotlib gradio ipykernel pip langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5823b62",
   "metadata": {},
   "source": [
    "## Step 2: The Application Code (`app.py`)\n",
    "\n",
    "### 2.1 - Imports and Configuration\n",
    "\n",
    "First, we import all the necessary libraries. We need `gradio` for the UI, `pandas` for data handling, `os` for file operations, and `langchain` components to build and run our agent. We also define a constant for the filename of our plots to keep the code clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI  # Changed from OpenAI to ChatOpenAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "# --- Load Environment Variables ---\n",
    "# This line reads the .env file and loads the variables into the environment\n",
    "load_dotenv()\n",
    "# --- Configuration ---\n",
    "# Define a constant for the plot filename to ensure consistency.\n",
    "PLOT_FILENAME = \"temp_analysis_plot.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2324f9",
   "metadata": {},
   "source": [
    "### 2.2 - The Agent Logic Function\n",
    "\n",
    "Next, we define the main function, `data_analyst_agent`. This function will be called by Gradio every time the user clicks the \"Run Analysis\" button. It takes the uploaded file and the user's text prompt as input.\n",
    "\n",
    "The first part of the function handles input validation and cleans up any old plot files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analyst_agent(file_obj, user_prompt):\n",
    "    \"\"\"\n",
    "    This is the core function that orchestrates the agent's work.\n",
    "    \"\"\"\n",
    "    # 1. Input Validation\n",
    "    if file_obj is None:\n",
    "        return \"Error: Please upload a CSV file first.\", None\n",
    "    if not user_prompt:\n",
    "        return \"Error: Please enter a question or instruction.\", None\n",
    "\n",
    "    # 2. Cleanup: Remove any old plot file to prevent showing stale results.\n",
    "    if os.path.exists(PLOT_FILENAME):\n",
    "        os.remove(PLOT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec117af",
   "metadata": {},
   "source": [
    "### 2.3 - Create and Execute the Agent\n",
    "\n",
    "This is the core of the function. We create an instance of the `create_pandas_dataframe_agent`, which is specifically designed to work with data in a pandas DataFrame.\n",
    "\n",
    "We then create a detailed prompt that includes the user's original question plus specific instructions for the agent, telling it to save any plots it makes. This makes the agent much more reliable. Finally, we `invoke` the agent to run the analysis and handle any errors that might occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load Data: The file_obj from Gradio has a .name attribute\n",
    "    # which holds the temporary path to the uploaded file.\n",
    "    df = pd.read_csv(file_obj.name)\n",
    "\n",
    "    # Initialize LLM: Use a chat model that supports tool calling.\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=api_key, \n",
    "        temperature=0, \n",
    "        model=\"gpt-3.5-turbo\" # Specify a tool-calling model\n",
    "    )\n",
    "\n",
    "    # Create Agent: This is the heart of the operation.\n",
    "    # `create_pandas_dataframe_agent` equips the LLM with tools\n",
    "    # to execute pandas operations on the DataFrame.\n",
    "    agent_executor = create_pandas_dataframe_agent(\n",
    "        llm,\n",
    "        df,\n",
    "        agent_type=\"openai-tools\",\n",
    "        verbose=True,  # Set to True to see the agent's thought process in the terminal\n",
    "        allow_dangerous_code=True # Opt-in to allow the agent to execute Python code\n",
    "    )\n",
    "\n",
    "    # Craft a Detailed Prompt: We augment the user's prompt to give the\n",
    "    # agent explicit instructions on how to handle visualizations.\n",
    "    # This makes the agent much more reliable.\n",
    "    full_prompt = f\"\"\"\n",
    "    User Question: {user_prompt}\n",
    "\n",
    "    Instructions for the agent:\n",
    "    - First, analyze the provided data to answer the user's question.\n",
    "    - If you generate a plot or visualization, you MUST save it as a file named '{PLOT_FILENAME}'.\n",
    "    - In your final answer, you must explicitly describe the visualization you created (e.g., \"I have created a bar chart that shows the total sales for each product category.\").\n",
    "    - Also, mention that the plot has been saved.\n",
    "    - Use Markdown formatting for all text in your output. This includes headings, bullet points, code blocks (if any), and emphasis for clarity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Run the Agent: Invoke the agent with the detailed prompt.\n",
    "    response = agent_executor.invoke({\"input\": full_prompt})\n",
    "    \n",
    "    # Extract the text output from the agent's response.\n",
    "    text_output = response.get('output', \"I couldn't generate a text response. Please check the logs.\")\n",
    "\n",
    "    # Check for and Return the Plot: After the agent runs, check if the\n",
    "    # plot file was created. If so, return it alongside the text answer.\n",
    "    if os.path.exists(PLOT_FILENAME):\n",
    "        return text_output, PLOT_FILENAME\n",
    "    else:\n",
    "        # If no plot was created, return None for the image output.\n",
    "        return text_output, None\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    \n",
    "    error_message = f\"An unexpected error occurred: {str(e)}\"\n",
    "    print(error_message) \n",
    "    return error_message, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e0410",
   "metadata": {},
   "source": [
    "### 2.4 - Building the Gradio UI\n",
    "\n",
    "Finally, we create the web interface. We use `gr.Blocks` for a custom layout. We define the input components (`gr.File`, `gr.Textbox`) and the output components (`gr.Markdown`, `gr.Image`).\n",
    "\n",
    "The most important line is `submit_button.click(...)`. This tells Gradio that when the button is clicked, it should call our `data_analyst_agent` function, passing the content from the input components to it and sending the function's results to the output components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\")) as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # 🤖 Agentic Data Analysis with LangChain\n",
    "        Upload your CSV file, ask a question in natural language, and the AI agent will work to find the answer.\n",
    "        It can perform calculations, data manipulation, and even generate visualizations.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            # Input components\n",
    "            file_input = gr.File(label=\"Upload your CSV\", file_types=[\".csv\"])\n",
    "            text_input = gr.Textbox(\n",
    "                label=\"What would you like to know?\",\n",
    "                placeholder=\"e.g., 'What is the correlation between column A and B?' or 'Create a bar chart of sales by category.'\"\n",
    "            )\n",
    "            submit_button = gr.Button(\"🚀 Run Analysis\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            # Output components\n",
    "            text_output = gr.Markdown(label=\"📝 Agent's Answer\")\n",
    "            plot_output = gr.Image(label=\"📊 Generated Visualization\", type=\"filepath\")\n",
    "\n",
    "    # Connect the button to the agent function\n",
    "    submit_button.click(\n",
    "        fn=data_analyst_agent,\n",
    "        inputs=[file_input, text_input],\n",
    "        outputs=[text_output, plot_output]\n",
    "    )\n",
    "    \n",
    "# To run this app, save it as app.py and run 'uv run app.py' in your terminal.\n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6453c951",
   "metadata": {},
   "source": [
    "## Step 3: Running the Application\n",
    "\n",
    "To run the app, use `uv` to execute the script from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to spawn: `app.py`\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: program not found\n"
     ]
    }
   ],
   "source": [
    "!uv run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
